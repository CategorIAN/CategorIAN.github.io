---
title: "CSCI 447 Project 1: Naive Bayes"
---

<h1>References</h1>
GitHub Repository: <a href = "https://github.com/CategorIAN/CSCI447_Project_1">here</a>

<h1>Description</h1>

<p>
For my first project in my Machine Learning course, my partner, Ethan Skelton, and I focused on creating a Naive Bayes supervised learning model. Our algorithm trains a model using a real world data set to predict the class of examples from the same data set. The examples used to train the model make up the training data, and the examples that had their classes predicted from the model make up the test data. The assignment of training data and test data for any given data set was created from 10-fold cross validation. 
</p>

<p>
For a given training set, for each class, we computed
\[
Q(C=c_i) = \dfrac{\#\{\textbf{x}\in c_i\}}{N},
\]
where \\[N\\] is the number of examples in the training set. Then, for each attribute and each class, we calculate, 
\[
F(A_j = a_k, C=c_i) = \dfrac{\#\{(\textbf{x}_{A_j} = a_k) \wedge (\textbf{x} \in c_i)\} +1}{N_{c_i} + d}.
\]
</p>
